colnames(d18Omat) <- paste("Sim", seq(1, N, 1), sep = "")
D47mat <- as.data.frame(matrix(rnorm(N * length(D47), D47, SD_D47), ncol = N)) # Randomly resample D47 data using measurement uncertainty
colnames(D47mat) <- paste("Sim", seq(1, N, 1), sep = "")
max(ages)
ceiling(max(ages))
floor(range(ages))
floor(diff(range(ages))
)
ceiling(diff(range(ages))
)
?runMean
require(TTR)
?runMean
?apply
if(length(d18Oc) / ceiling(diff(range(ages))) < 2){ # If there are less than 2 datapoints per year, the window is allowed to become as long as the entire record
win <- seq(1, length(d18Oc), 1)
}else{
win <- seq(1, length(d18O_mod) / ceiling(diff(range(ages))), 1) # Create vector of sample size windows (max sample size is 1 year)
}
if(length(d18Oc) / ceiling(diff(range(ages))) < 2){ # If there are less than 2 datapoints per year, the window is allowed to become as long as the entire record
win <- seq(1, length(d18Oc), 1)
}else{
win <- seq(1, length(d18Oc) / ceiling(diff(range(ages))), 1) # Create vector of sample size windows (max sample size is 1 year)
}
Dwin <- apply(d18Omat, 2, max(runMean(win)))
View(d18Omat)
Dwin <- apply(d18Omat, 2, max(runMean(, win)))
Dwin <- apply(d18Omat, 2, function(x) max(runMean(x, win)))
Dwin <- apply(D47mat, 2, function(x) max(TTR::runMean(x, win))) # Find highest D47 values (winter)
Dsum <- apply(D47mat, 2, function(x) min(TTR::runMean(x, win))) # Find lowest D47 values (summer)
dwin <- apply(d18Omat, 2, function(x) max(TTR::runMean(x, win))) # Find highest d18O values (winter)
dsum <- apply(d18Omat, 2, function(x) min(TTR::runMean(x, win))) # Find lowest d18O values (summer)
Dwinsd <- apply(D47mat, 2, function(x) TTR::runSD(x, win)[which.max(TTR::runMean(x, win))])
?runMean
Dwinsd <- apply(D47mat, 2, function(x) TTR::runSD(x, win)[which.max(TTR::runMean(x, win), na.rm = TRUE)])
if(length(d18Oc) / ceiling(diff(range(ages))) < 2){ # If there are less than 2 datapoints per year, the window is allowed to become as long as the entire record
win <- seq(2, length(d18Oc), 1)
}else{
win <- seq(2, length(d18Oc) / ceiling(diff(range(ages))), 1) # Create vector of sample size windows (max sample size is 1 year)
}
Dwin <- apply(D47mat, 2, function(x) max(TTR::runMean(x, win))) # Find highest D47 values (winter)
Dsum <- apply(D47mat, 2, function(x) min(TTR::runMean(x, win))) # Find lowest D47 values (summer)
dwin <- apply(d18Omat, 2, function(x) max(TTR::runMean(x, win))) # Find highest d18O values (winter)
dsum <- apply(d18Omat, 2, function(x) min(TTR::runMean(x, win))) # Find lowest d18O values (summer)
Dwin <- apply(D47mat, 2, function(x) max(TTR::runMean(x, win), na.rm = TRUE))
Dwin <- apply(D47mat, 2, function(x) max(TTR::runMean(x, win), na.rm = TRUE)) # Find highest D47 values (winter)
Dsum <- apply(D47mat, 2, function(x) min(TTR::runMean(x, win), na.rm = TRUE)) # Find lowest D47 values (summer)
dwin <- apply(d18Omat, 2, function(x) max(TTR::runMean(x, win), na.rm = TRUE)) # Find highest d18O values (winter)
dsum <- apply(d18Omat, 2, function(x) min(TTR::runMean(x, win), na.rm = TRUE)) # Find lowest d18O values (summer)
Dwinsd <- apply(D47mat, 2, function(x) TTR::runSD(x, win)[which.max(TTR::runMean(x, win))])
Dsumsd <- apply(D47mat, 2, function(x) TTR::runSD(x, win)[which.min(TTR::runMean(x, win))]) # Find standard deviation of summer D47 values
x11(9))); plot(Dwinsd)
x11(); plot(Dwinsd)
x11(); plot(Dsumsd)
dwinsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, win)[which.max(TTR::runMean(x, win))]) # Find standard deviation of winter d18O values
dsumsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, win)[which.min(TTR::runMean(x, win))]) # Find standard deviation of summer d18O values
Dwin2 <- apply(D47mat, 2, function(x) max(TTR::runMean(x, 2), na.rm = TRUE))
Dwin3 <- apply(D47mat, 2, function(x) max(TTR::runMean(x, 3), na.rm = TRUE))
Dwin3 <- apply(D47mat, 2, function(x) max(TTR::runMean(x, 1), na.rm = TRUE))
Dwin3 <- apply(D47mat, 2, function(x) max(TTR::runMean(x, 10), na.rm = TRUE))
test <- 1:10
runMean(test, win)
runMean(test, 2)
runMean(test, 3)
runMean(test, 3, cumulative = TRUE)
runMean(test, 3)
runMean(test, 2)
runMean(test, 2.5)
recond <- ages # Create matrix for d18O results
reconD <- ages # Create matrix for D47 results
for(i in win){
# Progress
cat(paste("Optimizing moving average window size: ",i),"\r")
flush.console()
Dwin <- apply(D47mat, 2, function(x) max(TTR::runMean(x, i), na.rm = TRUE)) # Find highest D47 values (winter)
Dsum <- apply(D47mat, 2, function(x) min(TTR::runMean(x, i), na.rm = TRUE)) # Find lowest D47 values (summer)
dwin <- apply(d18Omat, 2, function(x) max(TTR::runMean(x, i), na.rm = TRUE)) # Find highest d18O values (winter)
dsum <- apply(d18Omat, 2, function(x) min(TTR::runMean(x, i), na.rm = TRUE)) # Find lowest d18O values (summer)
Dwinsd <- apply(D47mat, 2, function(x) TTR::runSD(x, i)[which.max(TTR::runMean(x, i))]) # Find standard deviation of winter D47 values
Dsumsd <- apply(D47mat, 2, function(x) TTR::runSD(x, i)[which.min(TTR::runMean(x, i))]) # Find standard deviation of summer D47 values
dwinsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, i)[which.max(TTR::runMean(x, i))]) # Find standard deviation of winter d18O values
dsumsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, i)[which.min(TTR::runMean(x, i))]) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each simulation
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / i)) # Calculate two-sample T-value for each simulation (equal sample size, equal variance)
Pval <- pt(T, i - 1) # Calculate p-value for each window
Popt <- rbind(Popt, c(rep(i, length(which(Pval < p))),
length(which(Pval < p)),
min(Pval, na.rm = TRUE),
dsum[which(Pval < p)],
dwin[which(Pval < p)],
Dsum[which(Pval < p)],
Dwin[which(Pval < p)]))
}
View(Popt)
length(which(!is.na(Popt)))
devtools::document()
load("C:/Users/niels/Dropbox/Research/postdoc/UNBIAS/seasonalclumped/data/Case1.rda")
d18Oc <- Case1[, 29]
d18Oc <- d18Oc[-which(is.na(d18Oc))]
D47 <- Case1[, 30]
D47 <- D47[-which(is.na(D47))]
ages <- Case1[, 27]
ages <- ages[-which(is.na(ages))]
SD_d18Oc = 0.1 # Error (1 SD) on d18Oc data
SD_D47 = 0.04 # Error (1 SD) on D47 data
N = 1000 # Number of Monte Carlo simulations for optimization
p = 0.05 # p-value threshold for considering successful separation of seasons
d18O_fun = "KimONeil97"
D47_fun = "Bernasconi18"
export = FALSE # Should the result be exported?
export_raw = FALSE
# Prepare data
# Check if data has equal length
if(length(unique(c(length(d18Oc), length(D47), length(ages)))) > 1){
return("ERROR: Vectors 'd18Oc', 'D47' and 'ages' should have equal length")
}
Popt <- matrix(NA, ncol = 5, nrow = N * length(d18Oc)) # Create matrix with maximum length
colnames(Popt) <- c("optimal sample size",
"number of successful simulations for this sample size",
"Optimum p-value for this sample size",
"dOsum",
"dOwin",
"Dsum",
"Dwin") # Create template for storing simulation results
if(length(SD_d18Oc) == 1){
SD_d18Oc <- rep(SD_d18Oc, length(d18Oc)) # Duplicate SD of d18Oc error through entire record length if only a single value is given (constant uncertainty)
}
if(length(SD_D47) == 1){
SD_D47 <- rep(SD_D47, length(D47)) # Duplicate SD of D47 error through entire record length if only a single value is given (constant uncertainty)
}
d18Omat <- as.data.frame(matrix(rnorm(N * length(d18Oc), d18Oc, SD_d18Oc), ncol = N)) # Randomly resample d18O data using measurement uncertainty
colnames(d18Omat) <- paste("Sim", seq(1, N, 1), sep = "")
D47mat <- as.data.frame(matrix(rnorm(N * length(D47), D47, SD_D47), ncol = N)) # Randomly resample D47 data using measurement uncertainty
colnames(D47mat) <- paste("Sim", seq(1, N, 1), sep = "")
# Expanding moving average window
if(length(d18Oc) / ceiling(diff(range(ages))) < 2){ # If there are less than 2 datapoints per year, the window is allowed to become as long as the entire record
win <- seq(2, length(d18Oc), 1)
}else{
win <- seq(2, length(d18Oc) / ceiling(diff(range(ages))), 1) # Create vector of sample size windows (max sample size is 1 year)
}
if(length(unique(c(length(d18Oc), length(D47), length(ages)))) > 1){
return("ERROR: Vectors 'd18Oc', 'D47' and 'ages' should have equal length")
}
Popt <- matrix(NA, ncol = 7, nrow = N * length(d18Oc)) # Create matrix with maximum length
colnames(Popt) <- c("optimal sample size",
"number of successful simulations for this sample size",
"Optimum p-value for this sample size",
"dOsum",
"dOwin",
"Dsum",
"Dwin") # Create template for storing simulation results
if(length(SD_d18Oc) == 1){
SD_d18Oc <- rep(SD_d18Oc, length(d18Oc)) # Duplicate SD of d18Oc error through entire record length if only a single value is given (constant uncertainty)
}
if(length(SD_D47) == 1){
SD_D47 <- rep(SD_D47, length(D47)) # Duplicate SD of D47 error through entire record length if only a single value is given (constant uncertainty)
}
d18Omat <- as.data.frame(matrix(rnorm(N * length(d18Oc), d18Oc, SD_d18Oc), ncol = N)) # Randomly resample d18O data using measurement uncertainty
colnames(d18Omat) <- paste("Sim", seq(1, N, 1), sep = "")
D47mat <- as.data.frame(matrix(rnorm(N * length(D47), D47, SD_D47), ncol = N)) # Randomly resample D47 data using measurement uncertainty
colnames(D47mat) <- paste("Sim", seq(1, N, 1), sep = "")
# Expanding moving average window
if(length(d18Oc) / ceiling(diff(range(ages))) < 2){ # If there are less than 2 datapoints per year, the window is allowed to become as long as the entire record
win <- seq(2, length(d18Oc), 1)
}else{
win <- seq(2, length(d18Oc) / ceiling(diff(range(ages))), 1) # Create vector of sample size windows (max sample size is 1 year)
}
View(Popt)
row = 1 # Increment rows in Popt matrix for data storage, start with 1
for(i in win){
# Progress
cat(paste("Optimizing moving average window size: ",i),"\r")
flush.console()
Dwin <- apply(D47mat, 2, function(x) max(TTR::runMean(x, i), na.rm = TRUE)) # Find highest D47 values (winter)
Dsum <- apply(D47mat, 2, function(x) min(TTR::runMean(x, i), na.rm = TRUE)) # Find lowest D47 values (summer)
dwin <- apply(d18Omat, 2, function(x) max(TTR::runMean(x, i), na.rm = TRUE)) # Find highest d18O values (winter)
dsum <- apply(d18Omat, 2, function(x) min(TTR::runMean(x, i), na.rm = TRUE)) # Find lowest d18O values (summer)
Dwinsd <- apply(D47mat, 2, function(x) TTR::runSD(x, i)[which.max(TTR::runMean(x, i))]) # Find standard deviation of winter D47 values
Dsumsd <- apply(D47mat, 2, function(x) TTR::runSD(x, i)[which.min(TTR::runMean(x, i))]) # Find standard deviation of summer D47 values
dwinsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, i)[which.max(TTR::runMean(x, i))]) # Find standard deviation of winter d18O values
dsumsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, i)[which.min(TTR::runMean(x, i))]) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each simulation
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / i)) # Calculate two-sample T-value for each simulation (equal sample size, equal variance)
Pval <- pt(T, i - 1) # Calculate p-value for each window
Popt[row:(row + length(which(Pval < p)) - 1), ] <- c(rep(i, length(which(Pval < p))),
length(which(Pval < p)),
min(Pval, na.rm = TRUE),
dsum[which(Pval < p)],
dwin[which(Pval < p)],
Dsum[which(Pval < p)],
Dwin[which(Pval < p)])
row = row + length(which(Pval < p)
}
row = 1 # Increment rows in Popt matrix for data storage, start with 1
for(i in win){
# Progress
cat(paste("Optimizing moving average window size: ",i),"\r")
flush.console()
Dwin <- apply(D47mat, 2, function(x) max(TTR::runMean(x, i), na.rm = TRUE)) # Find highest D47 values (winter)
Dsum <- apply(D47mat, 2, function(x) min(TTR::runMean(x, i), na.rm = TRUE)) # Find lowest D47 values (summer)
dwin <- apply(d18Omat, 2, function(x) max(TTR::runMean(x, i), na.rm = TRUE)) # Find highest d18O values (winter)
dsum <- apply(d18Omat, 2, function(x) min(TTR::runMean(x, i), na.rm = TRUE)) # Find lowest d18O values (summer)
Dwinsd <- apply(D47mat, 2, function(x) TTR::runSD(x, i)[which.max(TTR::runMean(x, i))]) # Find standard deviation of winter D47 values
Dsumsd <- apply(D47mat, 2, function(x) TTR::runSD(x, i)[which.min(TTR::runMean(x, i))]) # Find standard deviation of summer D47 values
dwinsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, i)[which.max(TTR::runMean(x, i))]) # Find standard deviation of winter d18O values
dsumsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, i)[which.min(TTR::runMean(x, i))]) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each simulation
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / i)) # Calculate two-sample T-value for each simulation (equal sample size, equal variance)
Pval <- pt(T, i - 1) # Calculate p-value for each window
Popt[row:(row + length(which(Pval < p)) - 1), ] <- c(rep(i, length(which(Pval < p))),
length(which(Pval < p)),
min(Pval, na.rm = TRUE),
dsum[which(Pval < p)],
dwin[which(Pval < p)],
Dsum[which(Pval < p)],
Dwin[which(Pval < p)])
row = row + length(which(Pval < p))
}
require(TTR)
install.packages("TTR")
row = 1 # Increment rows in Popt matrix for data storage, start with 1
for(i in win){
# Progress
cat(paste("Optimizing moving average window size: ",i),"\r")
flush.console()
Dwin <- apply(D47mat, 2, function(x) max(TTR::runMean(x, i), na.rm = TRUE)) # Find highest D47 values (winter)
Dsum <- apply(D47mat, 2, function(x) min(TTR::runMean(x, i), na.rm = TRUE)) # Find lowest D47 values (summer)
dwin <- apply(d18Omat, 2, function(x) max(TTR::runMean(x, i), na.rm = TRUE)) # Find highest d18O values (winter)
dsum <- apply(d18Omat, 2, function(x) min(TTR::runMean(x, i), na.rm = TRUE)) # Find lowest d18O values (summer)
Dwinsd <- apply(D47mat, 2, function(x) TTR::runSD(x, i)[which.max(TTR::runMean(x, i))]) # Find standard deviation of winter D47 values
Dsumsd <- apply(D47mat, 2, function(x) TTR::runSD(x, i)[which.min(TTR::runMean(x, i))]) # Find standard deviation of summer D47 values
dwinsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, i)[which.max(TTR::runMean(x, i))]) # Find standard deviation of winter d18O values
dsumsd <- apply(d18Omat, 2, function(x) TTR::runSD(x, i)[which.min(TTR::runMean(x, i))]) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each simulation
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / i)) # Calculate two-sample T-value for each simulation (equal sample size, equal variance)
Pval <- pt(T, i - 1) # Calculate p-value for each window
Popt[row:(row + length(which(Pval < p)) - 1), ] <- c(rep(i, length(which(Pval < p))),
length(which(Pval < p)),
min(Pval, na.rm = TRUE),
dsum[which(Pval < p)],
dwin[which(Pval < p)],
Dsum[which(Pval < p)],
Dwin[which(Pval < p)])
row = row + length(which(Pval < p))
}
recond <- ages # Create matrix for d18O results
reconD <- ages # Create matrix for D47 results
i=1
Dwin <- vapply(win, function(x) max(TTR::runMean(D47mat[, i], x), na.rm = TRUE))
Dwin <- vapply(win, function(x) max(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1)
vapply(win, function(x) min(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1)
Dwinsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.max(TTR::runMean(D47mat[, i], x))])
Dwinsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.max(TTR::runMean(D47mat[, i], x))], 1)
Popt <- matrix(NA, ncol = 7, nrow = N * length(d18Oc)) # Create matrix with maximum length
colnames(Popt) <- c("optimal sample size",
"number of successful simulations",
"Optimum p-value",
"dOsum",
"dOwin",
"Dsum",
"Dwin") # Create template for storing simulation results
Popt <- matrix(NA, ncol = 7, nrow = N) # Create matrix with maximum length
colnames(Popt) <- c("optimal sample size",
"number of successful simulations",
"Optimum p-value",
"dOsum",
"dOwin",
"Dsum",
"Dwin") # Create template for storing simulation results
for(i in 1:N){
# Progress
cat(paste("Optimizing moving average iteration: ",i),"\r")
flush.console()
Dwin <- vapply(win, function(x) max(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find highest D47 values (winter)
Dsum <- vapply(win, function(x) min(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find lowest D47 values (summer)
dwin <- vapply(win, function(x) max(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find highest d18O values (winter)
dsum <- vapply(win, function(x) min(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find lowest d18O values (summer)
Dwinsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.max(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of winter D47 values
Dsumsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.min(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of summer D47 values
dwinsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.max(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of winter d18O values
dsumsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.min(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each moving average window
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / win)) # Calculate two-sample T-value for each window (equal sample size, equal variance)
Pval <- pt(T, win - 1) # Calculate p-value for each window
Popt[i, ] <- c(win[which(Pval == min(Pval, na.rm = TRUE))],
length(which(Pval < 0.05)),
min(Pval, na.rm = TRUE),
dsum[which(Pval == min(Pval, na.rm = TRUE))],
dwin[which(Pval == min(Pval, na.rm = TRUE))],
Dsum[which(Pval == min(Pval, na.rm = TRUE))],
Dwin[which(Pval == min(Pval, na.rm = TRUE))])
}
shift <- round(win[which(Pval == min(Pval, na.rm = TRUE))] / 2, 0)
recond <- cbind(ages, matrix(NA, Ncol = N, nrow = length(ages))) # Create matrix for d18O results
reconD <- cbind(ages, matrix(NA, Ncol = N, nrow = length(ages)))
recond <- cbind(ages, matrix(NA, ncol = N, nrow = length(ages))) # Create matrix for d18O results
reconD <- cbind(ages, matrix(NA, ncol = N, nrow = length(ages)))
View(recond)
Popt <- matrix(NA, ncol = 7, nrow = N) # Create matrix with maximum length
colnames(Popt) <- c("optimal sample size",
"number of successful simulations",
"Optimum p-value",
"dOsum",
"dOwin",
"Dsum",
"Dwin") # Create template for storing simulation results
for(i in 1:N){
# Progress
cat(paste("Optimizing moving average iteration: ",i),"\r")
flush.console()
Dwin <- vapply(win, function(x) max(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find highest D47 values (winter)
Dsum <- vapply(win, function(x) min(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find lowest D47 values (summer)
dwin <- vapply(win, function(x) max(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find highest d18O values (winter)
dsum <- vapply(win, function(x) min(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find lowest d18O values (summer)
Dwinsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.max(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of winter D47 values
Dsumsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.min(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of summer D47 values
dwinsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.max(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of winter d18O values
dsumsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.min(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each moving average window
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / win)) # Calculate two-sample T-value for each window (equal sample size, equal variance)
Pval <- pt(T, win - 1) # Calculate p-value for each window
Popt[i, ] <- c(win[which(Pval == min(Pval, na.rm = TRUE))],
length(which(Pval < 0.05)),
min(Pval, na.rm = TRUE),
dsum[which(Pval == min(Pval, na.rm = TRUE))],
dwin[which(Pval == min(Pval, na.rm = TRUE))],
Dsum[which(Pval == min(Pval, na.rm = TRUE))],
Dwin[which(Pval == min(Pval, na.rm = TRUE))])
# Shift reconstructed time series to correct for offset due to right-ordered moving average
shift <- round(win[which(Pval == min(Pval, na.rm = TRUE))] / 2, 0)
recond[, i + 1] <- c(TTR::runMean(d18Omat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(d18Omat[, i])], rep(NA, shift)) # Collect best moving window d18Oc data into matrix for export
reconD[, i + 1] <- c(TTR::runMean(D47mat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(D47mat[, i])], rep(NA, shift)) # Collect best moving window D47 data into matrix for export
}
?runMean
test <- c(1,2,3,4,5,6,7,8,9)
runMean(test, 3)
TTR::runMean(test, 3)
shift <- round(3 / 2, 0)
TTR::runMean(test, 5)
shift <- round(5 / 2, 0)
shift <- round(6 / 2, 0)
shift <- round(3 / 2, 0)
round(5 / 2, 0)
round(3 / 2, 0)
round(1.5, 0)
round(2.5, 0)
round(3.5, 0)
round(3.4, 0)
round(2.5, 0)
round(2.6, 0)
recond <- matrix(NA, ncol = N, nrow = length(ages)) # Create matrix for d18O results
reconD <- matrix(NA, ncol = N, nrow = length(ages)) # Create matrix for D47 results
for(i in 1:N){
# Progress
cat(paste("Optimizing moving average iteration: ",i),"\r")
flush.console()
Dwin <- vapply(win, function(x) max(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find highest D47 values (winter)
Dsum <- vapply(win, function(x) min(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find lowest D47 values (summer)
dwin <- vapply(win, function(x) max(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find highest d18O values (winter)
dsum <- vapply(win, function(x) min(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find lowest d18O values (summer)
Dwinsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.max(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of winter D47 values
Dsumsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.min(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of summer D47 values
dwinsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.max(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of winter d18O values
dsumsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.min(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each moving average window
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / win)) # Calculate two-sample T-value for each window (equal sample size, equal variance)
Pval <- pt(T, win - 1) # Calculate p-value for each window
Popt[i, ] <- c(win[which(Pval == min(Pval, na.rm = TRUE))],
length(which(Pval < 0.05)),
min(Pval, na.rm = TRUE),
dsum[which(Pval == min(Pval, na.rm = TRUE))],
dwin[which(Pval == min(Pval, na.rm = TRUE))],
Dsum[which(Pval == min(Pval, na.rm = TRUE))],
Dwin[which(Pval == min(Pval, na.rm = TRUE))])
# Shift reconstructed time series to correct for offset due to right-ordered moving average
shift <- round(win[which(Pval == min(Pval, na.rm = TRUE))] / 2, 0)
recond[, i + 1] <- c(TTR::runMean(d18Omat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(d18Omat[, i])], rep(NA, shift)) # Collect best moving window d18Oc data into matrix for export
reconD[, i + 1] <- c(TTR::runMean(D47mat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(D47mat[, i])], rep(NA, shift)) # Collect best moving window D47 data into matrix for export
}
recond <- matrix(NA, ncol = N, nrow = length(ages)) # Create matrix for d18O results
reconD <- matrix(NA, ncol = N, nrow = length(ages)) # Create matrix for D47 results
for(i in 1:N){
# Progress
cat(paste("Optimizing moving average iteration: ",i),"\r")
flush.console()
Dwin <- vapply(win, function(x) max(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find highest D47 values (winter)
Dsum <- vapply(win, function(x) min(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find lowest D47 values (summer)
dwin <- vapply(win, function(x) max(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find highest d18O values (winter)
dsum <- vapply(win, function(x) min(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find lowest d18O values (summer)
Dwinsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.max(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of winter D47 values
Dsumsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.min(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of summer D47 values
dwinsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.max(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of winter d18O values
dsumsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.min(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each moving average window
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / win)) # Calculate two-sample T-value for each window (equal sample size, equal variance)
Pval <- pt(T, win - 1) # Calculate p-value for each window
Popt[i, ] <- c(win[which(Pval == min(Pval, na.rm = TRUE))],
length(which(Pval < 0.05)),
min(Pval, na.rm = TRUE),
dsum[which(Pval == min(Pval, na.rm = TRUE))],
dwin[which(Pval == min(Pval, na.rm = TRUE))],
Dsum[which(Pval == min(Pval, na.rm = TRUE))],
Dwin[which(Pval == min(Pval, na.rm = TRUE))])
# Shift reconstructed time series to correct for offset due to right-ordered moving average
shift <- round(win[which(Pval == min(Pval, na.rm = TRUE))] / 2, 0)
recond[, i] <- c(TTR::runMean(d18Omat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(d18Omat[, i])], rep(NA, shift)) # Collect best moving window d18Oc data into matrix for export
reconD[, i] <- c(TTR::runMean(D47mat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(D47mat[, i])], rep(NA, shift)) # Collect best moving window D47 data into matrix for export
}
View(recond)
recond$month <- ceiling((ages %% 1) * 12) # Use age data to group results into monthly bins
reconD$month <- ceiling((ages %% 1) * 12) # Use age data to group results into monthly bins
recond <- as.data.frame(matrix(NA, ncol = N, nrow = length(ages))) # Create matrix for d18O results
reconD <- as.data.frame(matrix(NA, ncol = N, nrow = length(ages))) # Create matrix for D47 results
colnames(recond) <- colnames(reconD) <- paste("Sim", seq(1, N, 1), sep = "")
for(i in 1:N){
# Progress
cat(paste("Optimizing moving average iteration: ",i),"\r")
flush.console()
Dwin <- vapply(win, function(x) max(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find highest D47 values (winter)
Dsum <- vapply(win, function(x) min(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find lowest D47 values (summer)
dwin <- vapply(win, function(x) max(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find highest d18O values (winter)
dsum <- vapply(win, function(x) min(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find lowest d18O values (summer)
Dwinsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.max(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of winter D47 values
Dsumsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.min(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of summer D47 values
dwinsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.max(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of winter d18O values
dsumsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.min(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each moving average window
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / win)) # Calculate two-sample T-value for each window (equal sample size, equal variance)
Pval <- pt(T, win - 1) # Calculate p-value for each window
Popt[i, ] <- c(win[which(Pval == min(Pval, na.rm = TRUE))],
length(which(Pval < 0.05)),
min(Pval, na.rm = TRUE),
dsum[which(Pval == min(Pval, na.rm = TRUE))],
dwin[which(Pval == min(Pval, na.rm = TRUE))],
Dsum[which(Pval == min(Pval, na.rm = TRUE))],
Dwin[which(Pval == min(Pval, na.rm = TRUE))])
# Shift reconstructed time series to correct for offset due to right-ordered moving average
shift <- round(win[which(Pval == min(Pval, na.rm = TRUE))] / 2, 0)
recond[, i] <- c(TTR::runMean(d18Omat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(d18Omat[, i])], rep(NA, shift)) # Collect best moving window d18Oc data into matrix for export
reconD[, i] <- c(TTR::runMean(D47mat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(D47mat[, i])], rep(NA, shift)) # Collect best moving window D47 data into matrix for export
}
recond$month <- ceiling((ages %% 1) * 12) # Use age data to group results into monthly bins
reconD$month <- ceiling((ages %% 1) * 12) # Use age data to group results into monthly bins
d18Oc_mean = vapply(1:12, function(x) mean(recond[which(recond$month == x), ]), 1)
warnings()
test <- recond[,-recond$month]
recond <- as.data.frame(matrix(NA, ncol = N, nrow = length(ages))) # Create matrix for d18O results
reconD <- as.data.frame(matrix(NA, ncol = N, nrow = length(ages))) # Create matrix for D47 results
colnames(recond) <- colnames(reconD) <- paste("Sim", seq(1, N, 1), sep = "")
for(i in 1:N){
# Progress
cat(paste("Optimizing moving average iteration: ",i),"\r")
flush.console()
Dwin <- vapply(win, function(x) max(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find highest D47 values (winter)
Dsum <- vapply(win, function(x) min(TTR::runMean(D47mat[, i], x), na.rm = TRUE), 1) # Find lowest D47 values (summer)
dwin <- vapply(win, function(x) max(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find highest d18O values (winter)
dsum <- vapply(win, function(x) min(TTR::runMean(d18Omat[, i], x), na.rm = TRUE), 1) # Find lowest d18O values (summer)
Dwinsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.max(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of winter D47 values
Dsumsd <- vapply(win, function(x) TTR::runSD(D47mat[, i], x)[which.min(TTR::runMean(D47mat[, i], x))], 1) # Find standard deviation of summer D47 values
dwinsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.max(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of winter d18O values
dsumsd <- vapply(win, function(x) TTR::runSD(d18Omat[, i], x)[which.min(TTR::runMean(d18Omat[, i], x))], 1) # Find standard deviation of summer d18O values
SDpool <- sqrt((Dsumsd ^ 2 + Dwinsd ^ 2) / 2) # Calculate pooled standard deviation for each moving average window
T <- (Dsum - Dwin) / (SDpool * sqrt(2 / win)) # Calculate two-sample T-value for each window (equal sample size, equal variance)
Pval <- pt(T, win - 1) # Calculate p-value for each window
Popt[i, ] <- c(win[which(Pval == min(Pval, na.rm = TRUE))],
length(which(Pval < 0.05)),
min(Pval, na.rm = TRUE),
dsum[which(Pval == min(Pval, na.rm = TRUE))],
dwin[which(Pval == min(Pval, na.rm = TRUE))],
Dsum[which(Pval == min(Pval, na.rm = TRUE))],
Dwin[which(Pval == min(Pval, na.rm = TRUE))])
# Shift reconstructed time series to correct for offset due to right-ordered moving average
shift <- round(win[which(Pval == min(Pval, na.rm = TRUE))] / 2, 0)
recond[, i] <- c(TTR::runMean(d18Omat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(d18Omat[, i])], rep(NA, shift)) # Collect best moving window d18Oc data into matrix for export
reconD[, i] <- c(TTR::runMean(D47mat[, i], win[which(Pval == min(Pval, na.rm=TRUE))])[(shift + 1):length(D47mat[, i])], rep(NA, shift)) # Collect best moving window D47 data into matrix for export
}
d18Oc_mean = vapply(1:12, function(x) mean(recond[which(month == x), ]), 1)
month <- ceiling((ages %% 1) * 12)
d18Oc_mean = vapply(1:12, function(x) mean(recond[which(month == x), ]), 1)
warnings()
d18Oc_mean = vapply(1:12, function(x) mean(recond[which(month == x), ], na.rm = TRUE), 1)
warnings()
d18Oc_mean = vapply(1:12, function(x) mean(as.numeric(recond[which(month == x), ]), na.rm = TRUE), 1)
mean(recond)
str(recond)
d18Oc_mean = vapply(1:12, function(x) mean(as.matrix(recond[which(month == x), ]), na.rm = TRUE), 1)
d18Oc_mean
d18Oc_monthly <- data.frame(d18Oc_mean = vapply(1:12, function(x) mean(as.matrix(recond[which(month == x), ]), na.rm = TRUE), 1),
d18Oc_median = vapply(1:12, function(x) median(as.matrix(recond[which(month == x), ]), na.rm = TRUE), 1),
d18Oc_SD = vapply(1:12, function(x) sd(as.matrix(recond[which(month == x), ]), na.rm = TRUE), 1)
)
d18Oc_monthly$d18Oc_SE <- d18Oc_monthly$d18Oc_SD / sqrt(vapply(1:12, function(x) length(as.matrix(recond[which(month == x), 1])), 1))
View(d18Oc_monthly)
D47_monthly <- data.frame(D47_mean = vapply(1:12, function(x) mean(as.matrix(reconD[which(month == x), ]), na.rm = TRUE), 1),
D47_median = vapply(1:12, function(x) median(as.matrix(reconD[which(month == x), ]), na.rm = TRUE), 1),
D47_SD = vapply(1:12, function(x) sd(as.matrix(reconD[which(month == x), ]), na.rm = TRUE), 1)
)
D47_monthly$D47_SE <- D47_monthly$D47_SD / sqrt(vapply(1:12, function(x) length(as.matrix(reconD[which(month == x), 1])), 1))
View(D47_monthly)
if(D47_fun == "Bernasconi18"){
T_monthly <- data.frame(T_mean = vapply(1:12, function(x) mean(sqrt((0.0449 * 10 ^ 6) / (as.matrix(reconD[which(month == x), ]) - 0.167)) - 273.15, na.rm = TRUE), 1),
T_median = vapply(1:12, function(x) median(sqrt((0.0449 * 10 ^ 6) / (as.matrix(reconD[which(month == x), ]) - 0.167)) - 273.15, na.rm = TRUE), 1),
T_SD = vapply(1:12, function(x) sd(sqrt((0.0449 * 10 ^ 6) / (as.matrix(reconD[which(month == x), ]) - 0.167)) - 273.15, na.rm = TRUE), 1)
)
}else if(D47_fun == "Jautzy20"){
T_monthly <- data.frame(T_mean = vapply(1:12, function(x) mean(sqrt((0.0433 * 10 ^ 6) / (as.matrix(reconD[which(month == x), ]) - 0.119 - 0.066)) - 273.15, na.rm = TRUE), 1),
T_median = vapply(1:12, function(x) median(sqrt((0.0433 * 10 ^ 6) / (as.matrix(reconD[which(month == x), ]) - 0.119 - 0.066)) - 273.15, na.rm = TRUE), 1),
T_SD = vapply(1:12, function(x) sd(sqrt((0.0433 * 10 ^ 6) / (as.matrix(reconD[which(month == x), ]) - 0.119 - 0.066)) - 273.15, na.rm = TRUE), 1)
)
}
View(T_monthly)
save.image("C:/Users/niels/Dropbox/Research/postdoc/UNBIAS/seasonalclumped/20201216.RData")
